\documentclass[12pt]{article}

\usepackage{../latex-sty/mypaper}
\newcommand{\bmu}{\boldsymbol{\mu}}
\newcommand{\blambda}{\boldsymbol{\lambda}}
\newcommand{\bLambda}{\boldsymbol{\Lambda}}
\usepackage[russian]{babel}
\newtheorem{Th}{Теорема}
\newtheorem{Ex}{Упражнение}
\author{Александр Катруца}
\title{Условия оптимальности и введение в теорию двойственности}


\begin{document}
\maketitle

\section{Условия оптимальности для выпуклых задач}

Условия оптимальности дают необходимые и/или достаточные условия минимума для выпуклых задач.
То есть формализуют поиск решения задачи минимизации и/или дают условия, при которых точка не является решением.
Отметим важный факт о решении задачи выпуклой оптимизации

\begin{Th}
Если $f$~--- выпуклая функция и $\bx^*$ точка локального минимума, то $\bx^*$ точка глобального минимума
\end{Th}

Рассмотрим два класса задач выпуклой оптимизации и сформулируем для них условия оптимальности.

\subsection{Безусловная оптимизация}

\begin{Th}
Для безусловной задачи выпуклой оптимизации вида 
\[
\min_{\bx \in \bbR^n} f(\bx),
\]
где $f$ дифференцируема, точка $\bx^*$ является решением тогда и только тогда, когда выполнено $f'(\bx^*) = 0$. 
\end{Th}

\subsection{Условная оптимизация} 

\begin{Th}
Для выпуклой задачи условной оптимизации вида
\begin{equation*}
\begin{split}
& \min f_0(\bx)\\
\mathrm{s.t. \;} & \bA\bx = \bfb \\
& f_i(\bx) \leq 0, \; i = 1,\ldots, p
\end{split}
\end{equation*}
где $f_i, \; i=0, \ldots, p$~--- выпуклые функции точка $\bx^*$ является решением тогда и только тогда, когда существуют вектора $\bmu^*$ и $\blambda^*$, такие что выполнены следующие условия
\begin{enumerate}
\item $f_i(\bx^*) \leq 0, \; i = 1,\ldots,p$
\item $\bA\bx^* = \bfb$
\item $\blambda^* \geq 0$
\item $\lambda_i^* f_i(\bx^*) = 0, \; i = 1,\ldots, p$
\item $L'_x (\bx^*, \blambda^*, \bmu^*) = 0$,
\end{enumerate}
где $L$~--- лагранжиан, который имеет вид
\[
L = f_0(\bx) + \bmu^{\T}(\bA\bx - \bfb) + \sum_{i=1}^p\lambda_i f_i(\bx)
\]
Эти условия называются условиями Каруша-Куна-Таккера, сокращённо ККТ. 
\end{Th}

Первые два условия означают, что $\bx^*$ лежит в допустимом множестве.
Последнее условие означает стационарность лагранжиана в точке $(\bx^*, \blambda^*, \bmu^*)$.
Условия 3 и 4 называются условиями допустимости в двойственной задачи и условием дополняющей нежёсткости, соответственно.
Откуда они берутся станет ясно после рассмотрения того, как строится двойственная задача и при каких условиях выполняется сильная двойственность. 

Обратите внимание на следующие три обстоятельства:
\begin{enumerate}
\item Если рассмотреть не выпуклую задачу, а произвольную, то можно записать аналогичные 5 условий. 
Однако в этом случае они будут только необходимыми, но не достаточными условиями минимума точки $\bx^*$
\item Слагаемые лагранжиана, в которые входят вектора $\bmu$ и $\blambda$, можно записать как скалярные произведения, поэтому аналогичные условия можно записать для выпуклых функции, заданных на некотором выпуклом множестве матриц.
В этом случае скалярное произведение будет записано для матриц в виде $\langle \bX, \bY \rangle = \mathrm{Tr}(\bX^{\T}\bY)$, а условие 3 превратится в условие неотрицательной определённости матрицы $\bLambda$.
\begin{Ex}
Запишите условия KKT для задачи нахождения матрицы ковариаций многомерного нормального распределения по принципу максимума правдоподобия при известном среднем.
\end{Ex}
\item Условие 4 можно переформулировать как альтернативу: либо $\lambda_i = 0$, либо $f_i(\bx^*) = 0$. 
Одновременное равенство нулю возможно, но не несёт в себе никакой новой информации, поскольку равенство 0 $\lambda_i$ означает, что градиент лагранжиана вырождается в градиент целевой функции, равенство нулю которого эквивалентно тому, что точка является решением. При этом $f_i(\bx^*)$ может быть равно нулю, но проверять это отдельно ненужно. Подробнее написано \href{https://mathoverflow.net/questions/248314/zero-lambda-zero-constraint-in-the-complementary-slackness-condition-of-the-kuh}{тут}.

\end{enumerate}

\section{Введение в теорию двойственности}

Теория двойственности позволяет переформулировать \emph{любую} задачу выпуклой оптимизации в виде \emph{выпуклой} задачи оптимизации (она называется двойственной), целевая функция которой оценивает снизу целевую функцию исходной задачи. 
Можно провести аналогию между двойственной задачей и описанием выпуклого множества как пересечения полупространств, образованных касательными гиперплоскостями в граничных точках множества.

Как строить выпуклую задачу в общем виде описано в \href{https://github.com/amkatrutsa/cet_opt_met/blob/master/05-KKT/05-KKT.pdf}{презентации}. 
Ниже расммотрены несколько примеров, для которых получим двойственную задачу и в некоторых случаях её аналитическое~(!) решение.

\subsection{Примеры}

\begin{enumerate}

\item Задача поиска решения недоопределённой системы линейных уравнений минимальной нормы
\begin{equation*}
\begin{split}
& \min \| \bx\|^2_2\\
\text{s.t. } & \bA\bx = \mathbf{b}
\end{split}
\end{equation*}
Запишем лагранжиан
\[
L = \|\bx\|_2^2 + \blambda^{\T} (\bA\bx - \bfb)
\]
Двойственная функция
\[
g(\blambda) = \min_{\bx} L(\bx, \blambda) = \min_{\bx} \|\bx\|_2^2 + \blambda^{\T} (\bA\bx - \bfb)
\]
В данном случае лагранжиан является выпуклой функцией по $\bx$, поэтому для нахождения минимума достаточно найти стационарные точки, то есть корни уравнения $L'_x = 0$:
\[
L'_x = 2\bx^* + \bA^{\T}\blambda = 0
\]
Тогда $\bx^* = -\frac{1}{2} \bA^{\T}\blambda$ и двойственная функция
\[
g(\lambda) = \frac{1}{4}\blambda^{\T}\bA\bA^{\T}\blambda - \frac{1}{2}\blambda^{\T} \bA\bA^{\T}\blambda - \blambda^{\T}\bfb = - \frac{1}{4}\blambda^{\T} \bA\bA^{\T}\blambda - \blambda^{\T}\bfb
\]
Заметим, что как и ожидалось из теории, она является вогнутой.
Двойственная задача примет вид 
\[
\max_{\blambda} - \frac{1}{4}\blambda^{\T} \bA\bA^{\T}\blambda - \blambda^{\T}\bfb
\]

Таким образом, выпуклую задачу с ограничениями типа равенства свели к выпуклой задачи без ограничений меньшей размерности.
В силу выпуклости исходной задачи выполняется сильная двойственность и решение прямой задачи можно легко восстановить из решения двойственной задачи по формуле $\bx^* = -\frac{1}{2} \bA^{\T}\blambda^*$.

Так как в исходной задаче нет ограничений типа неравенств, то отсутствуют условия дополняющей нежёсткости и ограничение на допустимость в двойственной задаче.

\item Задача линейного программирования

\begin{equation*}
\begin{split}
& \min \bc^{\T}\bx\\
\text{s.t. } & \bA\bx = \mathbf{b}\\
& \bx \geq 0
\end{split}
\end{equation*}

Лагранжиан 
\[
L = \bc^{\T}\bx + \bmu^{\T}(\bA\bx - \mathbf{b}) - \sum_{i=1}^n x_i\lambda_i = (\bc + \bA^{\T}\bmu - \blambda)^{\T}\bx - \bmu^{\T}\bfb.
\]
Лагранжиан снова выпуклая функция по $\bx$, точнее линейная, поэтому в общем случае она является неограниченной снизу.
Для того, чтобы минимуму лагранжиана был конечен необходимо наложить дополнительное ограничение $\bc + \bA^{\T}\bmu - \blambda = 0$.
Таким образом, двойственная функция примет вид
\[
g(\bmu, \blambda) = 
\begin{cases}
-\bfb^{\T}\bmu, & \bc + \bA^{\T}\bmu - \blambda = 0 \\
-\infty, & \text{otherwise}
\end{cases}
\]
Двойственная задача
\begin{equation*}
\begin{split}
& \min \bfb^{\T}\bmu\\
\mathrm{s.t.} & \bc + \bA^{\T}\bmu - \blambda = 0 \\
& \blambda \geq 0
\end{split}
\end{equation*}
или
\begin{equation*}
\begin{split}
& \min \bfb^{\T}\bmu\\
\mathrm{s.t.} & \bc + \bA^{\T}\bmu \geq 0 \\
\end{split}
\end{equation*}
Двойственная задача снова является задачей линейного программирования, но меньшей размерности, так как в матрице $\bA$ число строк меньше числа столбцов, и с меньшим числом ограничений.

Так как исходная задача была выпуклой, то выполняется сильная двойственность. 

\item Задача о разбиении

\begin{equation*}
\begin{split}
& \min \bx^{\T}\bW\bx\\
\text{s.t. } & x^2_i = 1, \; i = 1,\ldots,n,
\end{split}
\end{equation*}
где $\bW \in \bS^n$.

Обратите внимание что это задача дискретной оптимизации, то есть для её точного решения неизвестны быстрые алгоритмы, однако и для таких задач можно строить двойственные  задачи, которые будут выпуклыми и будут давать оценки снизу на оптимальные значения целевых функций в прямых задачах.

Итак, лагранжиан  для нашей задачи имеет вид
\[
L = \bx^{\T}\bW\bx + \sum_{i=1}^n \lambda_i(x_i^2 - 1) = \bx^{\T}(\bW + \mathrm{diag} (\blambda))\bx - \mathbf{1}^{\T}\blambda
\]

Лагранжиан является выпуклой функцией по $\bx$, если матрица $\bW + \mathrm{diag} (\blambda)$ неотрицательно определена, иначе лагранжиан является неограниченной снизу функцией и его минимум равен $-\infty$.
Таким образом, 
\[
g(\blambda) = 
\begin{cases}
- \mathbf{1}^{\T}\blambda, & \bW + \mathrm{diag} (\blambda) \succeq 0\\
-\infty, & \text{otherwise}
\end{cases}
\]

Двойственная задача имеет вид
\begin{equation*}
\begin{split}
& \min_{\blambda} \mathbf{1}^{\T}\blambda\\
\mathrm{s.t.} \; & \bW + \mathrm{diag} (\blambda) \succeq 0
\end{split}
\end{equation*}

Задача дискретной оптимизации была сведена к выпуклой задаче минимизации, решение которой даёт оценку снизу на оптимальное значение целевой функции в исходной задаче.

Также отметим, что для любого $\blambda$ из допустимого множества двойственная функция даёт оценку снизу на оптимальное значение исходной целевой функции.
Самым простым примером $\blambda$ из допустимого множества является вектор из минимальных собственных значений матрицы $\bW$ (проверьте почему?).
Соответственно значение $n\lambda_{\min}(\bW)$ оценивает снизу минимальное значение функции $\bx^{\T}\bW\bx$ для $x_i = \pm 1$.

Минимальное собственное значение матрицы можно найти за $\mathcal{O}(n^3)$ операций.
\end{enumerate}

\end{document}